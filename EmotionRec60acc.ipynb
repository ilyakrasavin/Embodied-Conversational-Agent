{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionRec60acc.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "osVm_sjft0eL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d10ba3ef-d399-45ca-cb51-17693e828027"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-d2SPVluGZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "910106d6-7ec2-4ae7-806f-60a02b49928e"
      },
      "source": [
        "import librosa\n",
        "from librosa import display\n",
        "%pylab inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['display']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYUN0WHTuQFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting features\n",
        "\n",
        "path = '/content/drive/My Drive/Audio_Speech_Actors_01-24'\n",
        "dataset_arr = []\n",
        "\n",
        "\n",
        "for patht, dir, fileset in os.walk(path):\n",
        "  for filename in fileset:\n",
        "    X, samp_rate = librosa.load(os.path.join(patht,filename), res_type='kaiser_fast')\n",
        "    #samp_rate = np.array(samp_rate)\n",
        "    \n",
        "    # MFCC\n",
        "    mfcc_val = np.mean(librosa.feature.mfcc(y=X, sr=samp_rate, n_mfcc=40), axis=1)\n",
        "\n",
        "    emo_num = filename[6:8]\n",
        "    arr_val = mfcc_val, emo_num\n",
        "\n",
        "    dataset_arr.append(arr_val)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TfLZ7zGuVsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "32b768fe-1408-4bbf-f521-dc920fb2d186"
      },
      "source": [
        "X, y = zip(*dataset_arr)\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "print(X.shape)\n",
        "print(type(X))\n",
        "print(y.shape)\n",
        "print(type(y))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1440, 40)\n",
            "<class 'numpy.ndarray'>\n",
            "(1440,)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0KBCI-Rua5Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cdd6761e-47aa-4e14-ef6d-89d867ef6ab3"
      },
      "source": [
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.67)\n",
        "\n",
        "x_train_cnn = np.expand_dims(X_train, axis=2)\n",
        "x_test_cnn = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "print(x_train_cnn.shape)\n",
        "print(x_test_cnn.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(964, 40, 1)\n",
            "(476, 40, 1)\n",
            "(964, 8)\n",
            "(476, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh6Gia0Yudm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv1D, MaxPooling1D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(256, 5, padding='same', input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2])))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 5, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=8))\n",
        "model.add(Conv1D(128, 5, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 5, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjmAf-oYugWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "e9dcddc1-cfff-4387-c352-35f4b92d7f7c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 40, 256)           1536      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 40, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 40, 128)           163968    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 40, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 40, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 5, 128)            82048     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 5, 128)            82048     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 5128      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 334,728\n",
            "Trainable params: 334,728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vG00cCduiIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20925559-cc6a-45b4-8983-4d513b8493e8"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "model_convnet = model.fit(x_train_cnn, y_train, batch_size=16, epochs=500, validation_data=(x_test_cnn, y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 3.8935 - accuracy: 0.1276 - val_loss: 2.6415 - val_accuracy: 0.1471\n",
            "Epoch 2/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 2.2811 - accuracy: 0.1338 - val_loss: 2.0621 - val_accuracy: 0.1450\n",
            "Epoch 3/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 2.1303 - accuracy: 0.1919 - val_loss: 2.0632 - val_accuracy: 0.1345\n",
            "Epoch 4/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 2.0913 - accuracy: 0.1836 - val_loss: 1.9761 - val_accuracy: 0.2248\n",
            "Epoch 5/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 2.0879 - accuracy: 0.1743 - val_loss: 1.9604 - val_accuracy: 0.2332\n",
            "Epoch 6/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 2.0676 - accuracy: 0.1857 - val_loss: 1.9861 - val_accuracy: 0.2101\n",
            "Epoch 7/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 2.0484 - accuracy: 0.1888 - val_loss: 1.9248 - val_accuracy: 0.2311\n",
            "Epoch 8/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 2.0248 - accuracy: 0.2137 - val_loss: 1.9731 - val_accuracy: 0.2038\n",
            "Epoch 9/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 2.0138 - accuracy: 0.2178 - val_loss: 1.9800 - val_accuracy: 0.2206\n",
            "Epoch 10/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.9729 - accuracy: 0.2479 - val_loss: 1.9245 - val_accuracy: 0.2479\n",
            "Epoch 11/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.9912 - accuracy: 0.2158 - val_loss: 1.9028 - val_accuracy: 0.2710\n",
            "Epoch 12/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.9557 - accuracy: 0.2313 - val_loss: 1.9287 - val_accuracy: 0.2122\n",
            "Epoch 13/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.9276 - accuracy: 0.2490 - val_loss: 1.9620 - val_accuracy: 0.1996\n",
            "Epoch 14/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.9331 - accuracy: 0.2448 - val_loss: 1.8931 - val_accuracy: 0.2647\n",
            "Epoch 15/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.9110 - accuracy: 0.2687 - val_loss: 1.8804 - val_accuracy: 0.2731\n",
            "Epoch 16/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8976 - accuracy: 0.2676 - val_loss: 1.9030 - val_accuracy: 0.2836\n",
            "Epoch 17/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8968 - accuracy: 0.2718 - val_loss: 1.8780 - val_accuracy: 0.2836\n",
            "Epoch 18/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.8855 - accuracy: 0.2728 - val_loss: 1.8352 - val_accuracy: 0.3109\n",
            "Epoch 19/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8572 - accuracy: 0.2967 - val_loss: 1.8642 - val_accuracy: 0.2269\n",
            "Epoch 20/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8770 - accuracy: 0.2718 - val_loss: 1.8902 - val_accuracy: 0.2794\n",
            "Epoch 21/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8559 - accuracy: 0.2915 - val_loss: 1.8339 - val_accuracy: 0.2941\n",
            "Epoch 22/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.8546 - accuracy: 0.2780 - val_loss: 1.8450 - val_accuracy: 0.3193\n",
            "Epoch 23/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8414 - accuracy: 0.3102 - val_loss: 1.8420 - val_accuracy: 0.2374\n",
            "Epoch 24/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8505 - accuracy: 0.2915 - val_loss: 1.8721 - val_accuracy: 0.2416\n",
            "Epoch 25/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8249 - accuracy: 0.3008 - val_loss: 1.8525 - val_accuracy: 0.2710\n",
            "Epoch 26/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8266 - accuracy: 0.3050 - val_loss: 1.8518 - val_accuracy: 0.2983\n",
            "Epoch 27/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8118 - accuracy: 0.3216 - val_loss: 1.8096 - val_accuracy: 0.3109\n",
            "Epoch 28/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8161 - accuracy: 0.3185 - val_loss: 1.7971 - val_accuracy: 0.3319\n",
            "Epoch 29/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.8076 - accuracy: 0.3143 - val_loss: 1.8200 - val_accuracy: 0.2773\n",
            "Epoch 30/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 1.8034 - accuracy: 0.3122 - val_loss: 1.9362 - val_accuracy: 0.2101\n",
            "Epoch 31/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 1.7901 - accuracy: 0.3299 - val_loss: 1.8450 - val_accuracy: 0.2794\n",
            "Epoch 32/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 1.7885 - accuracy: 0.3205 - val_loss: 1.7883 - val_accuracy: 0.3508\n",
            "Epoch 33/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 1.7824 - accuracy: 0.3278 - val_loss: 1.7759 - val_accuracy: 0.3424\n",
            "Epoch 34/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.7818 - accuracy: 0.3309 - val_loss: 1.7623 - val_accuracy: 0.3298\n",
            "Epoch 35/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.7810 - accuracy: 0.3299 - val_loss: 1.8789 - val_accuracy: 0.3109\n",
            "Epoch 36/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.7720 - accuracy: 0.3257 - val_loss: 1.7916 - val_accuracy: 0.3193\n",
            "Epoch 37/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7668 - accuracy: 0.3268 - val_loss: 1.8569 - val_accuracy: 0.2710\n",
            "Epoch 38/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7621 - accuracy: 0.3423 - val_loss: 1.7728 - val_accuracy: 0.3340\n",
            "Epoch 39/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.7576 - accuracy: 0.3351 - val_loss: 1.7648 - val_accuracy: 0.3424\n",
            "Epoch 40/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7512 - accuracy: 0.3465 - val_loss: 1.7907 - val_accuracy: 0.3256\n",
            "Epoch 41/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7399 - accuracy: 0.3454 - val_loss: 1.7458 - val_accuracy: 0.3172\n",
            "Epoch 42/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7456 - accuracy: 0.3537 - val_loss: 1.7529 - val_accuracy: 0.3403\n",
            "Epoch 43/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7227 - accuracy: 0.3714 - val_loss: 1.7285 - val_accuracy: 0.3151\n",
            "Epoch 44/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7292 - accuracy: 0.3631 - val_loss: 1.7326 - val_accuracy: 0.3739\n",
            "Epoch 45/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7303 - accuracy: 0.3589 - val_loss: 1.7550 - val_accuracy: 0.3130\n",
            "Epoch 46/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7190 - accuracy: 0.3517 - val_loss: 1.7179 - val_accuracy: 0.3529\n",
            "Epoch 47/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7069 - accuracy: 0.3527 - val_loss: 1.7478 - val_accuracy: 0.3613\n",
            "Epoch 48/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7071 - accuracy: 0.3620 - val_loss: 1.7321 - val_accuracy: 0.3697\n",
            "Epoch 49/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7087 - accuracy: 0.3620 - val_loss: 1.7355 - val_accuracy: 0.3655\n",
            "Epoch 50/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6920 - accuracy: 0.3631 - val_loss: 1.7167 - val_accuracy: 0.3340\n",
            "Epoch 51/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.7022 - accuracy: 0.3631 - val_loss: 1.7049 - val_accuracy: 0.3466\n",
            "Epoch 52/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6858 - accuracy: 0.3869 - val_loss: 1.7502 - val_accuracy: 0.3487\n",
            "Epoch 53/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6803 - accuracy: 0.3703 - val_loss: 1.7407 - val_accuracy: 0.3445\n",
            "Epoch 54/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6949 - accuracy: 0.3755 - val_loss: 1.7362 - val_accuracy: 0.3613\n",
            "Epoch 55/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6765 - accuracy: 0.3859 - val_loss: 1.7182 - val_accuracy: 0.3382\n",
            "Epoch 56/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6781 - accuracy: 0.3828 - val_loss: 1.7365 - val_accuracy: 0.3466\n",
            "Epoch 57/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6770 - accuracy: 0.3869 - val_loss: 1.7408 - val_accuracy: 0.3529\n",
            "Epoch 58/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6575 - accuracy: 0.4004 - val_loss: 1.7242 - val_accuracy: 0.3025\n",
            "Epoch 59/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.6607 - accuracy: 0.3745 - val_loss: 1.6966 - val_accuracy: 0.3824\n",
            "Epoch 60/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.6513 - accuracy: 0.3817 - val_loss: 1.7447 - val_accuracy: 0.3277\n",
            "Epoch 61/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6547 - accuracy: 0.3952 - val_loss: 1.6807 - val_accuracy: 0.3929\n",
            "Epoch 62/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6443 - accuracy: 0.3859 - val_loss: 1.6804 - val_accuracy: 0.3761\n",
            "Epoch 63/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6405 - accuracy: 0.3859 - val_loss: 1.6925 - val_accuracy: 0.3571\n",
            "Epoch 64/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6439 - accuracy: 0.4108 - val_loss: 1.7059 - val_accuracy: 0.3382\n",
            "Epoch 65/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.6340 - accuracy: 0.3921 - val_loss: 1.6840 - val_accuracy: 0.3424\n",
            "Epoch 66/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6168 - accuracy: 0.4139 - val_loss: 1.7404 - val_accuracy: 0.3361\n",
            "Epoch 67/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 1.6303 - accuracy: 0.4025 - val_loss: 1.6638 - val_accuracy: 0.3739\n",
            "Epoch 68/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 1.6172 - accuracy: 0.3880 - val_loss: 1.6698 - val_accuracy: 0.3761\n",
            "Epoch 69/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.6175 - accuracy: 0.4066 - val_loss: 1.6809 - val_accuracy: 0.3950\n",
            "Epoch 70/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.6114 - accuracy: 0.4077 - val_loss: 1.6635 - val_accuracy: 0.4055\n",
            "Epoch 71/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6074 - accuracy: 0.3838 - val_loss: 1.6501 - val_accuracy: 0.4244\n",
            "Epoch 72/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.6141 - accuracy: 0.4160 - val_loss: 1.6636 - val_accuracy: 0.3803\n",
            "Epoch 73/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5999 - accuracy: 0.3973 - val_loss: 1.6964 - val_accuracy: 0.3739\n",
            "Epoch 74/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5973 - accuracy: 0.4243 - val_loss: 1.6977 - val_accuracy: 0.3529\n",
            "Epoch 75/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5871 - accuracy: 0.4066 - val_loss: 1.6924 - val_accuracy: 0.3340\n",
            "Epoch 76/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5899 - accuracy: 0.4170 - val_loss: 1.6300 - val_accuracy: 0.4097\n",
            "Epoch 77/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5809 - accuracy: 0.4232 - val_loss: 1.6739 - val_accuracy: 0.3508\n",
            "Epoch 78/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5896 - accuracy: 0.4077 - val_loss: 1.6543 - val_accuracy: 0.3782\n",
            "Epoch 79/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5785 - accuracy: 0.4305 - val_loss: 1.6501 - val_accuracy: 0.3761\n",
            "Epoch 80/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5670 - accuracy: 0.4212 - val_loss: 1.6260 - val_accuracy: 0.3992\n",
            "Epoch 81/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5678 - accuracy: 0.4398 - val_loss: 1.6878 - val_accuracy: 0.3697\n",
            "Epoch 82/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5750 - accuracy: 0.4243 - val_loss: 1.6971 - val_accuracy: 0.3214\n",
            "Epoch 83/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5676 - accuracy: 0.4326 - val_loss: 1.7011 - val_accuracy: 0.3613\n",
            "Epoch 84/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5632 - accuracy: 0.4139 - val_loss: 1.6207 - val_accuracy: 0.3971\n",
            "Epoch 85/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5620 - accuracy: 0.4098 - val_loss: 1.6313 - val_accuracy: 0.4118\n",
            "Epoch 86/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5491 - accuracy: 0.4326 - val_loss: 1.6577 - val_accuracy: 0.4055\n",
            "Epoch 87/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5517 - accuracy: 0.4419 - val_loss: 1.6582 - val_accuracy: 0.3782\n",
            "Epoch 88/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5350 - accuracy: 0.4336 - val_loss: 1.6178 - val_accuracy: 0.4076\n",
            "Epoch 89/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5386 - accuracy: 0.4429 - val_loss: 1.5947 - val_accuracy: 0.4370\n",
            "Epoch 90/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5469 - accuracy: 0.4346 - val_loss: 1.6128 - val_accuracy: 0.3887\n",
            "Epoch 91/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5309 - accuracy: 0.4315 - val_loss: 1.6002 - val_accuracy: 0.4055\n",
            "Epoch 92/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5312 - accuracy: 0.4533 - val_loss: 1.6393 - val_accuracy: 0.3845\n",
            "Epoch 93/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5177 - accuracy: 0.4512 - val_loss: 1.6035 - val_accuracy: 0.4118\n",
            "Epoch 94/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5264 - accuracy: 0.4523 - val_loss: 1.6187 - val_accuracy: 0.4013\n",
            "Epoch 95/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5160 - accuracy: 0.4544 - val_loss: 1.6321 - val_accuracy: 0.3782\n",
            "Epoch 96/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5152 - accuracy: 0.4274 - val_loss: 1.5741 - val_accuracy: 0.4286\n",
            "Epoch 97/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5042 - accuracy: 0.4647 - val_loss: 1.5953 - val_accuracy: 0.4244\n",
            "Epoch 98/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.4978 - accuracy: 0.4440 - val_loss: 1.6228 - val_accuracy: 0.4097\n",
            "Epoch 99/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.5001 - accuracy: 0.4647 - val_loss: 1.6009 - val_accuracy: 0.4139\n",
            "Epoch 100/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.5077 - accuracy: 0.4595 - val_loss: 1.6232 - val_accuracy: 0.3761\n",
            "Epoch 101/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.4818 - accuracy: 0.4606 - val_loss: 1.5931 - val_accuracy: 0.4013\n",
            "Epoch 102/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4916 - accuracy: 0.4544 - val_loss: 1.5663 - val_accuracy: 0.4391\n",
            "Epoch 103/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4892 - accuracy: 0.4647 - val_loss: 1.5786 - val_accuracy: 0.4391\n",
            "Epoch 104/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4813 - accuracy: 0.4523 - val_loss: 1.6143 - val_accuracy: 0.3908\n",
            "Epoch 105/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4837 - accuracy: 0.4658 - val_loss: 1.6208 - val_accuracy: 0.4160\n",
            "Epoch 106/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4717 - accuracy: 0.4585 - val_loss: 1.5581 - val_accuracy: 0.4349\n",
            "Epoch 107/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4724 - accuracy: 0.4606 - val_loss: 1.5738 - val_accuracy: 0.4286\n",
            "Epoch 108/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4753 - accuracy: 0.4554 - val_loss: 1.6217 - val_accuracy: 0.4076\n",
            "Epoch 109/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4620 - accuracy: 0.4668 - val_loss: 1.5608 - val_accuracy: 0.4265\n",
            "Epoch 110/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4637 - accuracy: 0.4886 - val_loss: 1.6321 - val_accuracy: 0.4013\n",
            "Epoch 111/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4613 - accuracy: 0.4678 - val_loss: 1.5893 - val_accuracy: 0.3929\n",
            "Epoch 112/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4552 - accuracy: 0.4637 - val_loss: 1.5605 - val_accuracy: 0.4202\n",
            "Epoch 113/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4681 - accuracy: 0.4803 - val_loss: 1.5372 - val_accuracy: 0.4454\n",
            "Epoch 114/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.4643 - accuracy: 0.4751 - val_loss: 1.5619 - val_accuracy: 0.4370\n",
            "Epoch 115/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.4538 - accuracy: 0.4678 - val_loss: 1.5378 - val_accuracy: 0.4370\n",
            "Epoch 116/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4477 - accuracy: 0.4865 - val_loss: 1.6774 - val_accuracy: 0.3235\n",
            "Epoch 117/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4480 - accuracy: 0.4627 - val_loss: 1.6292 - val_accuracy: 0.3761\n",
            "Epoch 118/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4383 - accuracy: 0.4917 - val_loss: 1.5465 - val_accuracy: 0.4307\n",
            "Epoch 119/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4308 - accuracy: 0.4824 - val_loss: 1.5524 - val_accuracy: 0.4370\n",
            "Epoch 120/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4277 - accuracy: 0.4969 - val_loss: 1.5639 - val_accuracy: 0.4097\n",
            "Epoch 121/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4226 - accuracy: 0.4813 - val_loss: 1.5519 - val_accuracy: 0.4013\n",
            "Epoch 122/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4387 - accuracy: 0.4938 - val_loss: 1.5866 - val_accuracy: 0.4097\n",
            "Epoch 123/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4159 - accuracy: 0.4979 - val_loss: 1.5354 - val_accuracy: 0.4454\n",
            "Epoch 124/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4168 - accuracy: 0.4793 - val_loss: 1.5598 - val_accuracy: 0.3992\n",
            "Epoch 125/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4134 - accuracy: 0.4844 - val_loss: 1.5191 - val_accuracy: 0.4496\n",
            "Epoch 126/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4030 - accuracy: 0.4917 - val_loss: 1.5428 - val_accuracy: 0.4349\n",
            "Epoch 127/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4113 - accuracy: 0.4907 - val_loss: 1.5192 - val_accuracy: 0.4391\n",
            "Epoch 128/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4046 - accuracy: 0.4917 - val_loss: 1.5741 - val_accuracy: 0.4055\n",
            "Epoch 129/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3942 - accuracy: 0.5156 - val_loss: 1.5692 - val_accuracy: 0.4223\n",
            "Epoch 130/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.4014 - accuracy: 0.4896 - val_loss: 1.5436 - val_accuracy: 0.4349\n",
            "Epoch 131/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 1.3908 - accuracy: 0.5010 - val_loss: 1.5426 - val_accuracy: 0.4328\n",
            "Epoch 132/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3990 - accuracy: 0.5010 - val_loss: 1.5589 - val_accuracy: 0.4181\n",
            "Epoch 133/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.4003 - accuracy: 0.4927 - val_loss: 1.5598 - val_accuracy: 0.4349\n",
            "Epoch 134/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3832 - accuracy: 0.5021 - val_loss: 1.5284 - val_accuracy: 0.4328\n",
            "Epoch 135/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3760 - accuracy: 0.5093 - val_loss: 1.6472 - val_accuracy: 0.3908\n",
            "Epoch 136/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3917 - accuracy: 0.4938 - val_loss: 1.5597 - val_accuracy: 0.4076\n",
            "Epoch 137/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3839 - accuracy: 0.5093 - val_loss: 1.5173 - val_accuracy: 0.4349\n",
            "Epoch 138/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3728 - accuracy: 0.4959 - val_loss: 1.4982 - val_accuracy: 0.4559\n",
            "Epoch 139/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3639 - accuracy: 0.5062 - val_loss: 1.5431 - val_accuracy: 0.4454\n",
            "Epoch 140/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3779 - accuracy: 0.5062 - val_loss: 1.5550 - val_accuracy: 0.4034\n",
            "Epoch 141/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3669 - accuracy: 0.5021 - val_loss: 1.5040 - val_accuracy: 0.4433\n",
            "Epoch 142/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3612 - accuracy: 0.5301 - val_loss: 1.5218 - val_accuracy: 0.4223\n",
            "Epoch 143/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3644 - accuracy: 0.5104 - val_loss: 1.5071 - val_accuracy: 0.4517\n",
            "Epoch 144/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3559 - accuracy: 0.5124 - val_loss: 1.5230 - val_accuracy: 0.4475\n",
            "Epoch 145/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3613 - accuracy: 0.5031 - val_loss: 1.5184 - val_accuracy: 0.4559\n",
            "Epoch 146/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3513 - accuracy: 0.5332 - val_loss: 1.4889 - val_accuracy: 0.4643\n",
            "Epoch 147/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3613 - accuracy: 0.5280 - val_loss: 1.5080 - val_accuracy: 0.4202\n",
            "Epoch 148/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3569 - accuracy: 0.5145 - val_loss: 1.5620 - val_accuracy: 0.4034\n",
            "Epoch 149/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3556 - accuracy: 0.5114 - val_loss: 1.5033 - val_accuracy: 0.4265\n",
            "Epoch 150/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3530 - accuracy: 0.5073 - val_loss: 1.5204 - val_accuracy: 0.4223\n",
            "Epoch 151/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3415 - accuracy: 0.5249 - val_loss: 1.5037 - val_accuracy: 0.4496\n",
            "Epoch 152/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3336 - accuracy: 0.5332 - val_loss: 1.5278 - val_accuracy: 0.4307\n",
            "Epoch 153/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3487 - accuracy: 0.5332 - val_loss: 1.5074 - val_accuracy: 0.4370\n",
            "Epoch 154/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3291 - accuracy: 0.5259 - val_loss: 1.5452 - val_accuracy: 0.4286\n",
            "Epoch 155/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3406 - accuracy: 0.5197 - val_loss: 1.4818 - val_accuracy: 0.4601\n",
            "Epoch 156/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3374 - accuracy: 0.5093 - val_loss: 1.5245 - val_accuracy: 0.4244\n",
            "Epoch 157/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3405 - accuracy: 0.5176 - val_loss: 1.4764 - val_accuracy: 0.4517\n",
            "Epoch 158/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3310 - accuracy: 0.5311 - val_loss: 1.5318 - val_accuracy: 0.4076\n",
            "Epoch 159/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3172 - accuracy: 0.5280 - val_loss: 1.5193 - val_accuracy: 0.4244\n",
            "Epoch 160/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3266 - accuracy: 0.5000 - val_loss: 1.5183 - val_accuracy: 0.4286\n",
            "Epoch 161/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3112 - accuracy: 0.5508 - val_loss: 1.5950 - val_accuracy: 0.4223\n",
            "Epoch 162/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3277 - accuracy: 0.5104 - val_loss: 1.5164 - val_accuracy: 0.4181\n",
            "Epoch 163/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3143 - accuracy: 0.5187 - val_loss: 1.4577 - val_accuracy: 0.4748\n",
            "Epoch 164/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3119 - accuracy: 0.5342 - val_loss: 1.5037 - val_accuracy: 0.4286\n",
            "Epoch 165/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3130 - accuracy: 0.5363 - val_loss: 1.5330 - val_accuracy: 0.4349\n",
            "Epoch 166/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3070 - accuracy: 0.5218 - val_loss: 1.4580 - val_accuracy: 0.4601\n",
            "Epoch 167/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.3020 - accuracy: 0.5259 - val_loss: 1.4567 - val_accuracy: 0.4559\n",
            "Epoch 168/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3113 - accuracy: 0.5228 - val_loss: 1.4628 - val_accuracy: 0.4895\n",
            "Epoch 169/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2967 - accuracy: 0.5197 - val_loss: 1.5648 - val_accuracy: 0.3971\n",
            "Epoch 170/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.3028 - accuracy: 0.5228 - val_loss: 1.4507 - val_accuracy: 0.4328\n",
            "Epoch 171/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2852 - accuracy: 0.5197 - val_loss: 1.6162 - val_accuracy: 0.3824\n",
            "Epoch 172/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2823 - accuracy: 0.5488 - val_loss: 1.4502 - val_accuracy: 0.4706\n",
            "Epoch 173/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2824 - accuracy: 0.5311 - val_loss: 1.4385 - val_accuracy: 0.4832\n",
            "Epoch 174/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2814 - accuracy: 0.5322 - val_loss: 1.4260 - val_accuracy: 0.4895\n",
            "Epoch 175/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 1.2810 - accuracy: 0.5415 - val_loss: 1.5040 - val_accuracy: 0.4391\n",
            "Epoch 176/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 1.2842 - accuracy: 0.5373 - val_loss: 1.4635 - val_accuracy: 0.4727\n",
            "Epoch 177/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 1.2766 - accuracy: 0.5498 - val_loss: 1.4693 - val_accuracy: 0.4748\n",
            "Epoch 178/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 1.2833 - accuracy: 0.5436 - val_loss: 1.4575 - val_accuracy: 0.4853\n",
            "Epoch 179/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 1.2718 - accuracy: 0.5384 - val_loss: 1.5167 - val_accuracy: 0.4202\n",
            "Epoch 180/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2589 - accuracy: 0.5363 - val_loss: 1.4843 - val_accuracy: 0.4370\n",
            "Epoch 181/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2602 - accuracy: 0.5519 - val_loss: 1.4980 - val_accuracy: 0.4517\n",
            "Epoch 182/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2584 - accuracy: 0.5394 - val_loss: 1.5469 - val_accuracy: 0.3929\n",
            "Epoch 183/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2730 - accuracy: 0.5425 - val_loss: 1.4778 - val_accuracy: 0.4517\n",
            "Epoch 184/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2588 - accuracy: 0.5456 - val_loss: 1.4805 - val_accuracy: 0.4538\n",
            "Epoch 185/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2752 - accuracy: 0.5373 - val_loss: 1.4560 - val_accuracy: 0.4685\n",
            "Epoch 186/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2552 - accuracy: 0.5550 - val_loss: 1.4250 - val_accuracy: 0.5021\n",
            "Epoch 187/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2547 - accuracy: 0.5685 - val_loss: 1.4631 - val_accuracy: 0.4727\n",
            "Epoch 188/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2543 - accuracy: 0.5467 - val_loss: 1.4765 - val_accuracy: 0.4412\n",
            "Epoch 189/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2498 - accuracy: 0.5664 - val_loss: 1.4183 - val_accuracy: 0.4580\n",
            "Epoch 190/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2492 - accuracy: 0.5550 - val_loss: 1.4335 - val_accuracy: 0.4895\n",
            "Epoch 191/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2431 - accuracy: 0.5498 - val_loss: 1.4052 - val_accuracy: 0.4706\n",
            "Epoch 192/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2398 - accuracy: 0.5539 - val_loss: 1.4429 - val_accuracy: 0.4769\n",
            "Epoch 193/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2368 - accuracy: 0.5529 - val_loss: 1.4157 - val_accuracy: 0.4643\n",
            "Epoch 194/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2448 - accuracy: 0.5519 - val_loss: 1.4024 - val_accuracy: 0.5105\n",
            "Epoch 195/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2221 - accuracy: 0.5654 - val_loss: 1.5730 - val_accuracy: 0.3803\n",
            "Epoch 196/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2454 - accuracy: 0.5498 - val_loss: 1.4774 - val_accuracy: 0.4328\n",
            "Epoch 197/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2365 - accuracy: 0.5436 - val_loss: 1.3977 - val_accuracy: 0.4958\n",
            "Epoch 198/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2293 - accuracy: 0.5633 - val_loss: 1.4130 - val_accuracy: 0.5084\n",
            "Epoch 199/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2177 - accuracy: 0.5602 - val_loss: 1.4395 - val_accuracy: 0.4790\n",
            "Epoch 200/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2303 - accuracy: 0.5643 - val_loss: 1.5075 - val_accuracy: 0.4454\n",
            "Epoch 201/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2238 - accuracy: 0.5643 - val_loss: 1.4774 - val_accuracy: 0.4286\n",
            "Epoch 202/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2162 - accuracy: 0.5788 - val_loss: 1.3992 - val_accuracy: 0.4769\n",
            "Epoch 203/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2082 - accuracy: 0.5820 - val_loss: 1.3990 - val_accuracy: 0.4790\n",
            "Epoch 204/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2187 - accuracy: 0.5664 - val_loss: 1.3953 - val_accuracy: 0.4958\n",
            "Epoch 205/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2159 - accuracy: 0.5757 - val_loss: 1.4349 - val_accuracy: 0.4769\n",
            "Epoch 206/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2120 - accuracy: 0.5705 - val_loss: 1.3937 - val_accuracy: 0.5105\n",
            "Epoch 207/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2039 - accuracy: 0.5664 - val_loss: 1.5065 - val_accuracy: 0.4559\n",
            "Epoch 208/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2023 - accuracy: 0.5788 - val_loss: 1.4906 - val_accuracy: 0.4664\n",
            "Epoch 209/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1985 - accuracy: 0.5851 - val_loss: 1.4566 - val_accuracy: 0.4412\n",
            "Epoch 210/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 1.2133 - accuracy: 0.5861 - val_loss: 1.4072 - val_accuracy: 0.4937\n",
            "Epoch 211/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 1.2066 - accuracy: 0.5768 - val_loss: 1.5035 - val_accuracy: 0.4622\n",
            "Epoch 212/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.2114 - accuracy: 0.5560 - val_loss: 1.4476 - val_accuracy: 0.4433\n",
            "Epoch 213/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1949 - accuracy: 0.5954 - val_loss: 1.4113 - val_accuracy: 0.4916\n",
            "Epoch 214/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1931 - accuracy: 0.5788 - val_loss: 1.4193 - val_accuracy: 0.4916\n",
            "Epoch 215/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1792 - accuracy: 0.5996 - val_loss: 1.4035 - val_accuracy: 0.4937\n",
            "Epoch 216/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1966 - accuracy: 0.5726 - val_loss: 1.4583 - val_accuracy: 0.4517\n",
            "Epoch 217/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1946 - accuracy: 0.5778 - val_loss: 1.3728 - val_accuracy: 0.5189\n",
            "Epoch 218/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.2028 - accuracy: 0.5892 - val_loss: 1.3817 - val_accuracy: 0.4979\n",
            "Epoch 219/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1789 - accuracy: 0.5799 - val_loss: 1.4256 - val_accuracy: 0.4811\n",
            "Epoch 220/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1874 - accuracy: 0.5871 - val_loss: 1.4136 - val_accuracy: 0.4958\n",
            "Epoch 221/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1730 - accuracy: 0.5799 - val_loss: 1.3885 - val_accuracy: 0.5042\n",
            "Epoch 222/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1569 - accuracy: 0.6006 - val_loss: 1.4448 - val_accuracy: 0.4622\n",
            "Epoch 223/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1743 - accuracy: 0.5851 - val_loss: 1.4117 - val_accuracy: 0.4517\n",
            "Epoch 224/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1623 - accuracy: 0.6089 - val_loss: 1.3991 - val_accuracy: 0.4874\n",
            "Epoch 225/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1709 - accuracy: 0.5913 - val_loss: 1.4496 - val_accuracy: 0.4601\n",
            "Epoch 226/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1572 - accuracy: 0.5830 - val_loss: 1.3959 - val_accuracy: 0.4622\n",
            "Epoch 227/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1662 - accuracy: 0.5892 - val_loss: 1.4616 - val_accuracy: 0.4328\n",
            "Epoch 228/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1606 - accuracy: 0.5892 - val_loss: 1.3567 - val_accuracy: 0.5063\n",
            "Epoch 229/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1447 - accuracy: 0.6017 - val_loss: 1.3698 - val_accuracy: 0.4769\n",
            "Epoch 230/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1631 - accuracy: 0.5923 - val_loss: 1.3738 - val_accuracy: 0.4832\n",
            "Epoch 231/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 1.1625 - accuracy: 0.5985 - val_loss: 1.3570 - val_accuracy: 0.5252\n",
            "Epoch 232/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1549 - accuracy: 0.5830 - val_loss: 1.4519 - val_accuracy: 0.4517\n",
            "Epoch 233/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1592 - accuracy: 0.5985 - val_loss: 1.4306 - val_accuracy: 0.4874\n",
            "Epoch 234/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1623 - accuracy: 0.5902 - val_loss: 1.3508 - val_accuracy: 0.5147\n",
            "Epoch 235/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1412 - accuracy: 0.5965 - val_loss: 1.3957 - val_accuracy: 0.5084\n",
            "Epoch 236/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1462 - accuracy: 0.5975 - val_loss: 1.3506 - val_accuracy: 0.5084\n",
            "Epoch 237/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1537 - accuracy: 0.6048 - val_loss: 1.3921 - val_accuracy: 0.4727\n",
            "Epoch 238/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1255 - accuracy: 0.6131 - val_loss: 1.4228 - val_accuracy: 0.5000\n",
            "Epoch 239/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1461 - accuracy: 0.6017 - val_loss: 1.4286 - val_accuracy: 0.4685\n",
            "Epoch 240/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1351 - accuracy: 0.5975 - val_loss: 1.4127 - val_accuracy: 0.4706\n",
            "Epoch 241/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1472 - accuracy: 0.6048 - val_loss: 1.3845 - val_accuracy: 0.4937\n",
            "Epoch 242/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1445 - accuracy: 0.5788 - val_loss: 1.4123 - val_accuracy: 0.4664\n",
            "Epoch 243/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1316 - accuracy: 0.6048 - val_loss: 1.4229 - val_accuracy: 0.4832\n",
            "Epoch 244/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1362 - accuracy: 0.6172 - val_loss: 1.3687 - val_accuracy: 0.4748\n",
            "Epoch 245/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1184 - accuracy: 0.6110 - val_loss: 1.3821 - val_accuracy: 0.5147\n",
            "Epoch 246/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1243 - accuracy: 0.6006 - val_loss: 1.3488 - val_accuracy: 0.5063\n",
            "Epoch 247/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1180 - accuracy: 0.6100 - val_loss: 1.4339 - val_accuracy: 0.4895\n",
            "Epoch 248/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1357 - accuracy: 0.6027 - val_loss: 1.3360 - val_accuracy: 0.5357\n",
            "Epoch 249/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0976 - accuracy: 0.6183 - val_loss: 1.3349 - val_accuracy: 0.5336\n",
            "Epoch 250/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1060 - accuracy: 0.6203 - val_loss: 1.3522 - val_accuracy: 0.5315\n",
            "Epoch 251/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1165 - accuracy: 0.6089 - val_loss: 1.3531 - val_accuracy: 0.5252\n",
            "Epoch 252/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1062 - accuracy: 0.6255 - val_loss: 1.3832 - val_accuracy: 0.4937\n",
            "Epoch 253/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1140 - accuracy: 0.6193 - val_loss: 1.3521 - val_accuracy: 0.4895\n",
            "Epoch 254/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1120 - accuracy: 0.6089 - val_loss: 1.3804 - val_accuracy: 0.4958\n",
            "Epoch 255/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0976 - accuracy: 0.6214 - val_loss: 1.3660 - val_accuracy: 0.4874\n",
            "Epoch 256/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.1133 - accuracy: 0.5892 - val_loss: 1.3590 - val_accuracy: 0.4874\n",
            "Epoch 257/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1109 - accuracy: 0.6328 - val_loss: 1.3521 - val_accuracy: 0.5315\n",
            "Epoch 258/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1089 - accuracy: 0.6027 - val_loss: 1.3311 - val_accuracy: 0.5021\n",
            "Epoch 259/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1037 - accuracy: 0.6068 - val_loss: 1.3673 - val_accuracy: 0.5063\n",
            "Epoch 260/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0972 - accuracy: 0.6266 - val_loss: 1.4009 - val_accuracy: 0.5126\n",
            "Epoch 261/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0926 - accuracy: 0.6172 - val_loss: 1.3773 - val_accuracy: 0.4832\n",
            "Epoch 262/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0994 - accuracy: 0.6224 - val_loss: 1.3655 - val_accuracy: 0.5084\n",
            "Epoch 263/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0914 - accuracy: 0.6245 - val_loss: 1.3497 - val_accuracy: 0.5273\n",
            "Epoch 264/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0948 - accuracy: 0.6245 - val_loss: 1.3449 - val_accuracy: 0.5273\n",
            "Epoch 265/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0756 - accuracy: 0.6432 - val_loss: 1.3832 - val_accuracy: 0.5021\n",
            "Epoch 266/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0888 - accuracy: 0.6203 - val_loss: 1.3233 - val_accuracy: 0.5210\n",
            "Epoch 267/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0831 - accuracy: 0.6307 - val_loss: 1.3642 - val_accuracy: 0.4979\n",
            "Epoch 268/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0853 - accuracy: 0.6432 - val_loss: 1.3928 - val_accuracy: 0.5000\n",
            "Epoch 269/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0712 - accuracy: 0.6317 - val_loss: 1.3383 - val_accuracy: 0.5105\n",
            "Epoch 270/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.1020 - accuracy: 0.6245 - val_loss: 1.3226 - val_accuracy: 0.5252\n",
            "Epoch 271/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0749 - accuracy: 0.6286 - val_loss: 1.3587 - val_accuracy: 0.4811\n",
            "Epoch 272/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0801 - accuracy: 0.6276 - val_loss: 1.3359 - val_accuracy: 0.4958\n",
            "Epoch 273/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0673 - accuracy: 0.6255 - val_loss: 1.3954 - val_accuracy: 0.4685\n",
            "Epoch 274/500\n",
            "61/61 [==============================] - 4s 61ms/step - loss: 1.0623 - accuracy: 0.6297 - val_loss: 1.2997 - val_accuracy: 0.5525\n",
            "Epoch 275/500\n",
            "61/61 [==============================] - 4s 61ms/step - loss: 1.0688 - accuracy: 0.6400 - val_loss: 1.3753 - val_accuracy: 0.5021\n",
            "Epoch 276/500\n",
            "61/61 [==============================] - 3s 43ms/step - loss: 1.0621 - accuracy: 0.6297 - val_loss: 1.3242 - val_accuracy: 0.4895\n",
            "Epoch 277/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0776 - accuracy: 0.6255 - val_loss: 1.4154 - val_accuracy: 0.4685\n",
            "Epoch 278/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0801 - accuracy: 0.6151 - val_loss: 1.3589 - val_accuracy: 0.5336\n",
            "Epoch 279/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0677 - accuracy: 0.6369 - val_loss: 1.3064 - val_accuracy: 0.5210\n",
            "Epoch 280/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0548 - accuracy: 0.6369 - val_loss: 1.3738 - val_accuracy: 0.4832\n",
            "Epoch 281/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0597 - accuracy: 0.6535 - val_loss: 1.3856 - val_accuracy: 0.4895\n",
            "Epoch 282/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0571 - accuracy: 0.6494 - val_loss: 1.3404 - val_accuracy: 0.5168\n",
            "Epoch 283/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0565 - accuracy: 0.6400 - val_loss: 1.3457 - val_accuracy: 0.5189\n",
            "Epoch 284/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0568 - accuracy: 0.6266 - val_loss: 1.3322 - val_accuracy: 0.5189\n",
            "Epoch 285/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0518 - accuracy: 0.6234 - val_loss: 1.3690 - val_accuracy: 0.5084\n",
            "Epoch 286/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0473 - accuracy: 0.6286 - val_loss: 1.3698 - val_accuracy: 0.5000\n",
            "Epoch 287/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0412 - accuracy: 0.6421 - val_loss: 1.3480 - val_accuracy: 0.5294\n",
            "Epoch 288/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0506 - accuracy: 0.6452 - val_loss: 1.3766 - val_accuracy: 0.5105\n",
            "Epoch 289/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0417 - accuracy: 0.6483 - val_loss: 1.4398 - val_accuracy: 0.4391\n",
            "Epoch 290/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0398 - accuracy: 0.6390 - val_loss: 1.3403 - val_accuracy: 0.5273\n",
            "Epoch 291/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0404 - accuracy: 0.6452 - val_loss: 1.3715 - val_accuracy: 0.4979\n",
            "Epoch 292/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0353 - accuracy: 0.6452 - val_loss: 1.3421 - val_accuracy: 0.5294\n",
            "Epoch 293/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0397 - accuracy: 0.6494 - val_loss: 1.3542 - val_accuracy: 0.5189\n",
            "Epoch 294/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0273 - accuracy: 0.6494 - val_loss: 1.3657 - val_accuracy: 0.5126\n",
            "Epoch 295/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0267 - accuracy: 0.6608 - val_loss: 1.3872 - val_accuracy: 0.5021\n",
            "Epoch 296/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0260 - accuracy: 0.6369 - val_loss: 1.2964 - val_accuracy: 0.5210\n",
            "Epoch 297/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0356 - accuracy: 0.6390 - val_loss: 1.3112 - val_accuracy: 0.5315\n",
            "Epoch 298/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0222 - accuracy: 0.6587 - val_loss: 1.3270 - val_accuracy: 0.5084\n",
            "Epoch 299/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0235 - accuracy: 0.6566 - val_loss: 1.3129 - val_accuracy: 0.5210\n",
            "Epoch 300/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0208 - accuracy: 0.6473 - val_loss: 1.3073 - val_accuracy: 0.5210\n",
            "Epoch 301/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 1.0195 - accuracy: 0.6618 - val_loss: 1.3372 - val_accuracy: 0.5147\n",
            "Epoch 302/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0218 - accuracy: 0.6515 - val_loss: 1.3505 - val_accuracy: 0.4979\n",
            "Epoch 303/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0095 - accuracy: 0.6639 - val_loss: 1.3347 - val_accuracy: 0.5105\n",
            "Epoch 304/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0144 - accuracy: 0.6660 - val_loss: 1.3785 - val_accuracy: 0.4958\n",
            "Epoch 305/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0063 - accuracy: 0.6504 - val_loss: 1.3497 - val_accuracy: 0.5084\n",
            "Epoch 306/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0020 - accuracy: 0.6535 - val_loss: 1.3274 - val_accuracy: 0.5378\n",
            "Epoch 307/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0009 - accuracy: 0.6660 - val_loss: 1.3092 - val_accuracy: 0.5357\n",
            "Epoch 308/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0121 - accuracy: 0.6618 - val_loss: 1.3473 - val_accuracy: 0.5105\n",
            "Epoch 309/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9969 - accuracy: 0.6639 - val_loss: 1.3289 - val_accuracy: 0.5000\n",
            "Epoch 310/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0045 - accuracy: 0.6577 - val_loss: 1.3186 - val_accuracy: 0.5231\n",
            "Epoch 311/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0076 - accuracy: 0.6618 - val_loss: 1.2725 - val_accuracy: 0.5483\n",
            "Epoch 312/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 1.0043 - accuracy: 0.6556 - val_loss: 1.3944 - val_accuracy: 0.4874\n",
            "Epoch 313/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0011 - accuracy: 0.6608 - val_loss: 1.3136 - val_accuracy: 0.5378\n",
            "Epoch 314/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0149 - accuracy: 0.6608 - val_loss: 1.3373 - val_accuracy: 0.5063\n",
            "Epoch 315/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9879 - accuracy: 0.6680 - val_loss: 1.2714 - val_accuracy: 0.5399\n",
            "Epoch 316/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 1.0080 - accuracy: 0.6504 - val_loss: 1.2806 - val_accuracy: 0.5399\n",
            "Epoch 317/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.9989 - accuracy: 0.6618 - val_loss: 1.3064 - val_accuracy: 0.5504\n",
            "Epoch 318/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.9922 - accuracy: 0.6535 - val_loss: 1.3011 - val_accuracy: 0.5420\n",
            "Epoch 319/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.9844 - accuracy: 0.6639 - val_loss: 1.3129 - val_accuracy: 0.4979\n",
            "Epoch 320/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.9871 - accuracy: 0.6618 - val_loss: 1.2743 - val_accuracy: 0.5399\n",
            "Epoch 321/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 1.0009 - accuracy: 0.6598 - val_loss: 1.3375 - val_accuracy: 0.5441\n",
            "Epoch 322/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9859 - accuracy: 0.6722 - val_loss: 1.3342 - val_accuracy: 0.4958\n",
            "Epoch 323/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9684 - accuracy: 0.6836 - val_loss: 1.3172 - val_accuracy: 0.5420\n",
            "Epoch 324/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9833 - accuracy: 0.6639 - val_loss: 1.3215 - val_accuracy: 0.5525\n",
            "Epoch 325/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9916 - accuracy: 0.6712 - val_loss: 1.2960 - val_accuracy: 0.5483\n",
            "Epoch 326/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9834 - accuracy: 0.6680 - val_loss: 1.2839 - val_accuracy: 0.5420\n",
            "Epoch 327/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9730 - accuracy: 0.6784 - val_loss: 1.3503 - val_accuracy: 0.5000\n",
            "Epoch 328/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9752 - accuracy: 0.6774 - val_loss: 1.3819 - val_accuracy: 0.5126\n",
            "Epoch 329/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9828 - accuracy: 0.6670 - val_loss: 1.3300 - val_accuracy: 0.5147\n",
            "Epoch 330/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9685 - accuracy: 0.6712 - val_loss: 1.3318 - val_accuracy: 0.5231\n",
            "Epoch 331/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9658 - accuracy: 0.6712 - val_loss: 1.3599 - val_accuracy: 0.5063\n",
            "Epoch 332/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9789 - accuracy: 0.6680 - val_loss: 1.2961 - val_accuracy: 0.5063\n",
            "Epoch 333/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9639 - accuracy: 0.6878 - val_loss: 1.3835 - val_accuracy: 0.4979\n",
            "Epoch 334/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9776 - accuracy: 0.6649 - val_loss: 1.3107 - val_accuracy: 0.5294\n",
            "Epoch 335/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9612 - accuracy: 0.6846 - val_loss: 1.3531 - val_accuracy: 0.4664\n",
            "Epoch 336/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9568 - accuracy: 0.6691 - val_loss: 1.2999 - val_accuracy: 0.5525\n",
            "Epoch 337/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9508 - accuracy: 0.6888 - val_loss: 1.3113 - val_accuracy: 0.5105\n",
            "Epoch 338/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9452 - accuracy: 0.6701 - val_loss: 1.3376 - val_accuracy: 0.5063\n",
            "Epoch 339/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9439 - accuracy: 0.6898 - val_loss: 1.2825 - val_accuracy: 0.5126\n",
            "Epoch 340/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9572 - accuracy: 0.6940 - val_loss: 1.2950 - val_accuracy: 0.4979\n",
            "Epoch 341/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9525 - accuracy: 0.6805 - val_loss: 1.2852 - val_accuracy: 0.5294\n",
            "Epoch 342/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9473 - accuracy: 0.6795 - val_loss: 1.3132 - val_accuracy: 0.5315\n",
            "Epoch 343/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9561 - accuracy: 0.6795 - val_loss: 1.2619 - val_accuracy: 0.5483\n",
            "Epoch 344/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9426 - accuracy: 0.6909 - val_loss: 1.2824 - val_accuracy: 0.5357\n",
            "Epoch 345/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9449 - accuracy: 0.6867 - val_loss: 1.3675 - val_accuracy: 0.4958\n",
            "Epoch 346/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9359 - accuracy: 0.6846 - val_loss: 1.2970 - val_accuracy: 0.5273\n",
            "Epoch 347/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9381 - accuracy: 0.6753 - val_loss: 1.3515 - val_accuracy: 0.5231\n",
            "Epoch 348/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9483 - accuracy: 0.6867 - val_loss: 1.3231 - val_accuracy: 0.5063\n",
            "Epoch 349/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9297 - accuracy: 0.6940 - val_loss: 1.3012 - val_accuracy: 0.5315\n",
            "Epoch 350/500\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.9419 - accuracy: 0.6857 - val_loss: 1.2586 - val_accuracy: 0.5483\n",
            "Epoch 351/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.9266 - accuracy: 0.6940 - val_loss: 1.2807 - val_accuracy: 0.5273\n",
            "Epoch 352/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.9253 - accuracy: 0.7033 - val_loss: 1.3392 - val_accuracy: 0.5147\n",
            "Epoch 353/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9315 - accuracy: 0.7033 - val_loss: 1.2512 - val_accuracy: 0.5483\n",
            "Epoch 354/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9271 - accuracy: 0.6888 - val_loss: 1.2634 - val_accuracy: 0.5399\n",
            "Epoch 355/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9263 - accuracy: 0.6992 - val_loss: 1.3212 - val_accuracy: 0.5273\n",
            "Epoch 356/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9299 - accuracy: 0.6826 - val_loss: 1.3807 - val_accuracy: 0.5021\n",
            "Epoch 357/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9205 - accuracy: 0.7106 - val_loss: 1.2394 - val_accuracy: 0.5651\n",
            "Epoch 358/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9222 - accuracy: 0.7075 - val_loss: 1.2978 - val_accuracy: 0.5231\n",
            "Epoch 359/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9214 - accuracy: 0.6898 - val_loss: 1.2627 - val_accuracy: 0.5294\n",
            "Epoch 360/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9210 - accuracy: 0.6888 - val_loss: 1.2611 - val_accuracy: 0.5399\n",
            "Epoch 361/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9095 - accuracy: 0.7106 - val_loss: 1.2622 - val_accuracy: 0.5420\n",
            "Epoch 362/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9150 - accuracy: 0.6929 - val_loss: 1.3011 - val_accuracy: 0.5105\n",
            "Epoch 363/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9146 - accuracy: 0.7044 - val_loss: 1.2677 - val_accuracy: 0.5441\n",
            "Epoch 364/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9068 - accuracy: 0.7044 - val_loss: 1.3275 - val_accuracy: 0.5168\n",
            "Epoch 365/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9143 - accuracy: 0.7075 - val_loss: 1.4439 - val_accuracy: 0.4769\n",
            "Epoch 366/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9058 - accuracy: 0.6940 - val_loss: 1.2834 - val_accuracy: 0.5252\n",
            "Epoch 367/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9196 - accuracy: 0.6981 - val_loss: 1.3099 - val_accuracy: 0.5231\n",
            "Epoch 368/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9065 - accuracy: 0.7085 - val_loss: 1.3020 - val_accuracy: 0.5000\n",
            "Epoch 369/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8879 - accuracy: 0.7054 - val_loss: 1.3637 - val_accuracy: 0.4958\n",
            "Epoch 370/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.9121 - accuracy: 0.6950 - val_loss: 1.2873 - val_accuracy: 0.5546\n",
            "Epoch 371/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8880 - accuracy: 0.7095 - val_loss: 1.3413 - val_accuracy: 0.5084\n",
            "Epoch 372/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8924 - accuracy: 0.7116 - val_loss: 1.2419 - val_accuracy: 0.5525\n",
            "Epoch 373/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8912 - accuracy: 0.7023 - val_loss: 1.2864 - val_accuracy: 0.5210\n",
            "Epoch 374/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8870 - accuracy: 0.7002 - val_loss: 1.3074 - val_accuracy: 0.5462\n",
            "Epoch 375/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8883 - accuracy: 0.7054 - val_loss: 1.2719 - val_accuracy: 0.5210\n",
            "Epoch 376/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8916 - accuracy: 0.6940 - val_loss: 1.3903 - val_accuracy: 0.4958\n",
            "Epoch 377/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8890 - accuracy: 0.6940 - val_loss: 1.2960 - val_accuracy: 0.5231\n",
            "Epoch 378/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8845 - accuracy: 0.7168 - val_loss: 1.3888 - val_accuracy: 0.4811\n",
            "Epoch 379/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.9017 - accuracy: 0.7044 - val_loss: 1.3117 - val_accuracy: 0.4874\n",
            "Epoch 380/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8855 - accuracy: 0.7137 - val_loss: 1.2510 - val_accuracy: 0.5483\n",
            "Epoch 381/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8862 - accuracy: 0.6992 - val_loss: 1.2791 - val_accuracy: 0.5378\n",
            "Epoch 382/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8910 - accuracy: 0.7064 - val_loss: 1.3270 - val_accuracy: 0.4895\n",
            "Epoch 383/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8932 - accuracy: 0.7023 - val_loss: 1.2805 - val_accuracy: 0.5042\n",
            "Epoch 384/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8755 - accuracy: 0.7064 - val_loss: 1.3061 - val_accuracy: 0.5294\n",
            "Epoch 385/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8813 - accuracy: 0.7220 - val_loss: 1.3079 - val_accuracy: 0.5357\n",
            "Epoch 386/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8873 - accuracy: 0.7023 - val_loss: 1.2632 - val_accuracy: 0.5483\n",
            "Epoch 387/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8746 - accuracy: 0.7023 - val_loss: 1.2665 - val_accuracy: 0.5504\n",
            "Epoch 388/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8602 - accuracy: 0.7241 - val_loss: 1.2872 - val_accuracy: 0.4874\n",
            "Epoch 389/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8618 - accuracy: 0.7293 - val_loss: 1.3537 - val_accuracy: 0.5210\n",
            "Epoch 390/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8591 - accuracy: 0.7210 - val_loss: 1.2560 - val_accuracy: 0.5567\n",
            "Epoch 391/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8700 - accuracy: 0.7210 - val_loss: 1.2483 - val_accuracy: 0.5630\n",
            "Epoch 392/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8688 - accuracy: 0.7137 - val_loss: 1.2308 - val_accuracy: 0.5672\n",
            "Epoch 393/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8571 - accuracy: 0.7147 - val_loss: 1.3540 - val_accuracy: 0.5126\n",
            "Epoch 394/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8587 - accuracy: 0.7199 - val_loss: 1.2541 - val_accuracy: 0.5420\n",
            "Epoch 395/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8556 - accuracy: 0.7251 - val_loss: 1.2883 - val_accuracy: 0.5189\n",
            "Epoch 396/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8600 - accuracy: 0.7012 - val_loss: 1.3004 - val_accuracy: 0.5483\n",
            "Epoch 397/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8636 - accuracy: 0.7106 - val_loss: 1.2509 - val_accuracy: 0.5252\n",
            "Epoch 398/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8501 - accuracy: 0.7324 - val_loss: 1.3044 - val_accuracy: 0.5126\n",
            "Epoch 399/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8552 - accuracy: 0.7241 - val_loss: 1.2618 - val_accuracy: 0.5483\n",
            "Epoch 400/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8448 - accuracy: 0.7189 - val_loss: 1.2502 - val_accuracy: 0.5651\n",
            "Epoch 401/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8412 - accuracy: 0.7230 - val_loss: 1.2270 - val_accuracy: 0.5525\n",
            "Epoch 402/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8503 - accuracy: 0.7210 - val_loss: 1.3602 - val_accuracy: 0.5105\n",
            "Epoch 403/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8402 - accuracy: 0.7272 - val_loss: 1.2493 - val_accuracy: 0.5672\n",
            "Epoch 404/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8539 - accuracy: 0.7106 - val_loss: 1.2583 - val_accuracy: 0.5252\n",
            "Epoch 405/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8260 - accuracy: 0.7407 - val_loss: 1.2982 - val_accuracy: 0.5336\n",
            "Epoch 406/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8527 - accuracy: 0.7178 - val_loss: 1.2350 - val_accuracy: 0.5546\n",
            "Epoch 407/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8440 - accuracy: 0.7241 - val_loss: 1.2430 - val_accuracy: 0.5399\n",
            "Epoch 408/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8397 - accuracy: 0.7293 - val_loss: 1.2462 - val_accuracy: 0.5168\n",
            "Epoch 409/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8431 - accuracy: 0.7168 - val_loss: 1.2600 - val_accuracy: 0.5336\n",
            "Epoch 410/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8397 - accuracy: 0.7376 - val_loss: 1.2015 - val_accuracy: 0.5756\n",
            "Epoch 411/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8215 - accuracy: 0.7241 - val_loss: 1.2787 - val_accuracy: 0.5483\n",
            "Epoch 412/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8368 - accuracy: 0.7272 - val_loss: 1.2427 - val_accuracy: 0.5504\n",
            "Epoch 413/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8245 - accuracy: 0.7210 - val_loss: 1.2508 - val_accuracy: 0.5483\n",
            "Epoch 414/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8373 - accuracy: 0.7137 - val_loss: 1.2615 - val_accuracy: 0.5441\n",
            "Epoch 415/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8037 - accuracy: 0.7376 - val_loss: 1.2407 - val_accuracy: 0.5189\n",
            "Epoch 416/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8415 - accuracy: 0.7272 - val_loss: 1.2184 - val_accuracy: 0.5630\n",
            "Epoch 417/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8134 - accuracy: 0.7479 - val_loss: 1.2579 - val_accuracy: 0.5315\n",
            "Epoch 418/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8276 - accuracy: 0.7272 - val_loss: 1.2690 - val_accuracy: 0.5168\n",
            "Epoch 419/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8140 - accuracy: 0.7334 - val_loss: 1.2595 - val_accuracy: 0.5546\n",
            "Epoch 420/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8217 - accuracy: 0.7272 - val_loss: 1.2449 - val_accuracy: 0.5546\n",
            "Epoch 421/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8196 - accuracy: 0.7313 - val_loss: 1.2354 - val_accuracy: 0.5315\n",
            "Epoch 422/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8053 - accuracy: 0.7386 - val_loss: 1.2209 - val_accuracy: 0.5546\n",
            "Epoch 423/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.8240 - accuracy: 0.7344 - val_loss: 1.2523 - val_accuracy: 0.5210\n",
            "Epoch 424/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8207 - accuracy: 0.7272 - val_loss: 1.2700 - val_accuracy: 0.5252\n",
            "Epoch 425/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7947 - accuracy: 0.7293 - val_loss: 1.2262 - val_accuracy: 0.5735\n",
            "Epoch 426/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8109 - accuracy: 0.7334 - val_loss: 1.2503 - val_accuracy: 0.5441\n",
            "Epoch 427/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8007 - accuracy: 0.7448 - val_loss: 1.2609 - val_accuracy: 0.5609\n",
            "Epoch 428/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8149 - accuracy: 0.7448 - val_loss: 1.2879 - val_accuracy: 0.5231\n",
            "Epoch 429/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8108 - accuracy: 0.7365 - val_loss: 1.3159 - val_accuracy: 0.5294\n",
            "Epoch 430/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7932 - accuracy: 0.7427 - val_loss: 1.2553 - val_accuracy: 0.5273\n",
            "Epoch 431/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7898 - accuracy: 0.7324 - val_loss: 1.2220 - val_accuracy: 0.5693\n",
            "Epoch 432/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8088 - accuracy: 0.7261 - val_loss: 1.3046 - val_accuracy: 0.5168\n",
            "Epoch 433/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8078 - accuracy: 0.7334 - val_loss: 1.2287 - val_accuracy: 0.5483\n",
            "Epoch 434/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7995 - accuracy: 0.7459 - val_loss: 1.3060 - val_accuracy: 0.5378\n",
            "Epoch 435/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7868 - accuracy: 0.7552 - val_loss: 1.2592 - val_accuracy: 0.5546\n",
            "Epoch 436/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7951 - accuracy: 0.7396 - val_loss: 1.2292 - val_accuracy: 0.5567\n",
            "Epoch 437/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.8034 - accuracy: 0.7293 - val_loss: 1.2535 - val_accuracy: 0.5462\n",
            "Epoch 438/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7914 - accuracy: 0.7459 - val_loss: 1.2131 - val_accuracy: 0.5693\n",
            "Epoch 439/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7805 - accuracy: 0.7427 - val_loss: 1.3345 - val_accuracy: 0.5021\n",
            "Epoch 440/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7883 - accuracy: 0.7469 - val_loss: 1.2579 - val_accuracy: 0.5609\n",
            "Epoch 441/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7900 - accuracy: 0.7386 - val_loss: 1.2218 - val_accuracy: 0.5504\n",
            "Epoch 442/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7776 - accuracy: 0.7469 - val_loss: 1.2638 - val_accuracy: 0.5567\n",
            "Epoch 443/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7942 - accuracy: 0.7459 - val_loss: 1.2450 - val_accuracy: 0.5336\n",
            "Epoch 444/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7860 - accuracy: 0.7407 - val_loss: 1.2020 - val_accuracy: 0.5504\n",
            "Epoch 445/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7820 - accuracy: 0.7396 - val_loss: 1.2103 - val_accuracy: 0.5567\n",
            "Epoch 446/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7820 - accuracy: 0.7376 - val_loss: 1.1904 - val_accuracy: 0.5777\n",
            "Epoch 447/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.7822 - accuracy: 0.7500 - val_loss: 1.2048 - val_accuracy: 0.5630\n",
            "Epoch 448/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7667 - accuracy: 0.7593 - val_loss: 1.3201 - val_accuracy: 0.5210\n",
            "Epoch 449/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7797 - accuracy: 0.7344 - val_loss: 1.2697 - val_accuracy: 0.5441\n",
            "Epoch 450/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7784 - accuracy: 0.7386 - val_loss: 1.2684 - val_accuracy: 0.5399\n",
            "Epoch 451/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7796 - accuracy: 0.7541 - val_loss: 1.2718 - val_accuracy: 0.5273\n",
            "Epoch 452/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7693 - accuracy: 0.7656 - val_loss: 1.2203 - val_accuracy: 0.5588\n",
            "Epoch 453/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7564 - accuracy: 0.7469 - val_loss: 1.2041 - val_accuracy: 0.5651\n",
            "Epoch 454/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7700 - accuracy: 0.7635 - val_loss: 1.2151 - val_accuracy: 0.5693\n",
            "Epoch 455/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7566 - accuracy: 0.7666 - val_loss: 1.1911 - val_accuracy: 0.5651\n",
            "Epoch 456/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7663 - accuracy: 0.7635 - val_loss: 1.3177 - val_accuracy: 0.5357\n",
            "Epoch 457/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7740 - accuracy: 0.7448 - val_loss: 1.2865 - val_accuracy: 0.5378\n",
            "Epoch 458/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7691 - accuracy: 0.7521 - val_loss: 1.2042 - val_accuracy: 0.5714\n",
            "Epoch 459/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7498 - accuracy: 0.7604 - val_loss: 1.1841 - val_accuracy: 0.5630\n",
            "Epoch 460/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7700 - accuracy: 0.7438 - val_loss: 1.2117 - val_accuracy: 0.5735\n",
            "Epoch 461/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.7574 - accuracy: 0.7510 - val_loss: 1.3044 - val_accuracy: 0.5105\n",
            "Epoch 462/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.7568 - accuracy: 0.7531 - val_loss: 1.2553 - val_accuracy: 0.5294\n",
            "Epoch 463/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.7480 - accuracy: 0.7624 - val_loss: 1.2166 - val_accuracy: 0.5588\n",
            "Epoch 464/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.7503 - accuracy: 0.7552 - val_loss: 1.2456 - val_accuracy: 0.5672\n",
            "Epoch 465/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.7468 - accuracy: 0.7656 - val_loss: 1.2219 - val_accuracy: 0.5588\n",
            "Epoch 466/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.7363 - accuracy: 0.7656 - val_loss: 1.2402 - val_accuracy: 0.5693\n",
            "Epoch 467/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.7429 - accuracy: 0.7666 - val_loss: 1.1960 - val_accuracy: 0.5672\n",
            "Epoch 468/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.7336 - accuracy: 0.7728 - val_loss: 1.1991 - val_accuracy: 0.5819\n",
            "Epoch 469/500\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.7282 - accuracy: 0.7687 - val_loss: 1.2480 - val_accuracy: 0.5525\n",
            "Epoch 470/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.7366 - accuracy: 0.7510 - val_loss: 1.2424 - val_accuracy: 0.5693\n",
            "Epoch 471/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7384 - accuracy: 0.7728 - val_loss: 1.2316 - val_accuracy: 0.5462\n",
            "Epoch 472/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7394 - accuracy: 0.7635 - val_loss: 1.2115 - val_accuracy: 0.5840\n",
            "Epoch 473/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7449 - accuracy: 0.7624 - val_loss: 1.3220 - val_accuracy: 0.5357\n",
            "Epoch 474/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7433 - accuracy: 0.7728 - val_loss: 1.2398 - val_accuracy: 0.5546\n",
            "Epoch 475/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7494 - accuracy: 0.7614 - val_loss: 1.2154 - val_accuracy: 0.5756\n",
            "Epoch 476/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7373 - accuracy: 0.7604 - val_loss: 1.1725 - val_accuracy: 0.5924\n",
            "Epoch 477/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7448 - accuracy: 0.7645 - val_loss: 1.2118 - val_accuracy: 0.5252\n",
            "Epoch 478/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7258 - accuracy: 0.7645 - val_loss: 1.2828 - val_accuracy: 0.5483\n",
            "Epoch 479/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7309 - accuracy: 0.7759 - val_loss: 1.2130 - val_accuracy: 0.5378\n",
            "Epoch 480/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.7321 - accuracy: 0.7645 - val_loss: 1.2235 - val_accuracy: 0.5651\n",
            "Epoch 481/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7423 - accuracy: 0.7614 - val_loss: 1.1832 - val_accuracy: 0.5672\n",
            "Epoch 482/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7314 - accuracy: 0.7624 - val_loss: 1.2720 - val_accuracy: 0.5294\n",
            "Epoch 483/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7313 - accuracy: 0.7718 - val_loss: 1.1626 - val_accuracy: 0.5798\n",
            "Epoch 484/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7178 - accuracy: 0.7728 - val_loss: 1.1590 - val_accuracy: 0.5987\n",
            "Epoch 485/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7225 - accuracy: 0.7697 - val_loss: 1.2652 - val_accuracy: 0.5357\n",
            "Epoch 486/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7179 - accuracy: 0.7666 - val_loss: 1.2023 - val_accuracy: 0.5735\n",
            "Epoch 487/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7312 - accuracy: 0.7770 - val_loss: 1.2261 - val_accuracy: 0.5693\n",
            "Epoch 488/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7067 - accuracy: 0.7718 - val_loss: 1.2568 - val_accuracy: 0.5504\n",
            "Epoch 489/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7327 - accuracy: 0.7614 - val_loss: 1.2112 - val_accuracy: 0.5441\n",
            "Epoch 490/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7179 - accuracy: 0.7573 - val_loss: 1.2150 - val_accuracy: 0.5735\n",
            "Epoch 491/500\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.7189 - accuracy: 0.7687 - val_loss: 1.2016 - val_accuracy: 0.5903\n",
            "Epoch 492/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.7093 - accuracy: 0.7728 - val_loss: 1.2589 - val_accuracy: 0.5693\n",
            "Epoch 493/500\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.7158 - accuracy: 0.7645 - val_loss: 1.1860 - val_accuracy: 0.5777\n",
            "Epoch 494/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7165 - accuracy: 0.7739 - val_loss: 1.1962 - val_accuracy: 0.5735\n",
            "Epoch 495/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6977 - accuracy: 0.7780 - val_loss: 1.1729 - val_accuracy: 0.5756\n",
            "Epoch 496/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7109 - accuracy: 0.7759 - val_loss: 1.2275 - val_accuracy: 0.5546\n",
            "Epoch 497/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7149 - accuracy: 0.7842 - val_loss: 1.2172 - val_accuracy: 0.5735\n",
            "Epoch 498/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.7041 - accuracy: 0.7624 - val_loss: 1.2226 - val_accuracy: 0.5756\n",
            "Epoch 499/500\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6940 - accuracy: 0.7863 - val_loss: 1.2055 - val_accuracy: 0.5651\n",
            "Epoch 500/500\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7042 - accuracy: 0.7666 - val_loss: 1.3082 - val_accuracy: 0.5273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmi4KPZEunJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6707fd55-75e6-4085-fc45-59162ec77b8f"
      },
      "source": [
        " plt.plot(model_convnet.history['loss'])\n",
        " plt.plot(model_convnet.history['val_loss'])\n",
        " plt.title('model loss')\n",
        " plt.xlabel('epochs')\n",
        " plt.ylabel('loss')\n",
        " plt.legend(['train','test'], loc='upper left')\n",
        " plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3j2ZYYpvEFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f316b1fc-44e6-4855-83db-f9ee665ccb82"
      },
      "source": [
        "model_name = \"Speech_Emotion_Recognition.h5\"\n",
        "save_dir = os.path.join(os.getcwd(),'saved_cnn')\n",
        "if not os.path.isdir(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print(model_path)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/saved_cnn/Speech_Emotion_Recognition.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGvtTAe20bIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}